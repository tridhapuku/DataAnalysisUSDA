{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8650/3526851795.py:23: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,23,24,25,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(InputPath + FileName + InputFileExt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n",
      "1              TIMESTAMP   RECORD  Year Month Day_of_Month Day_of_Week  \\\n",
      "195  2023-09-22 09:33:46  3569875  2023     9           22           6   \n",
      "196  2023-09-22 09:33:47  3569876  2023     9           22           6   \n",
      "197  2023-09-22 09:33:48  3569877  2023     9           22           6   \n",
      "198  2023-09-22 09:33:49  3569878  2023     9           22           6   \n",
      "199  2023-09-22 09:33:50  3569879  2023     9           22           6   \n",
      "\n",
      "1   Day_of_Year Hour Minute Second  ...           CO2            H2O  \\\n",
      "195         265    9     33     46  ...  -0.007331962  -9.783333E-05   \n",
      "196         265    9     33     47  ...  -0.008423512  -0.0004874438   \n",
      "197         265    9     33     48  ...  -0.009412304   0.0001471807   \n",
      "198         265    9     33     49  ...  -0.007638384  -0.0001321673   \n",
      "199         265    9     33     50  ...  -0.008450584  -0.0002019428   \n",
      "\n",
      "1   wind_speed wind_direction diag IncomingSW OutgoingSW IncomingLW  \\\n",
      "195       0.44             85    0      310.6       82.8      341.5   \n",
      "196       0.42             75    0      353.4       95.9      342.2   \n",
      "197       0.45             82    0      353.4       95.9      342.2   \n",
      "198       0.46             87    0      353.4       95.9      342.2   \n",
      "199        0.5             92    0      353.4       95.9      342.2   \n",
      "\n",
      "1   OutgoingLW Albedo  \n",
      "195      439.4  0.267  \n",
      "196      439.6  0.267  \n",
      "197      439.6  0.271  \n",
      "198      439.6  0.271  \n",
      "199      439.6  0.271  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8650/3526851795.py:33: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,23,24,25,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(OutputPath + FileName + OutputFileExt,header=None)\n"
     ]
    }
   ],
   "source": [
    "#Try with bad data -- \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "############Configurable Parameters#############\n",
    "FileName = \"TOA5_ExProcessing\"\n",
    "InputPath = \"FromPramod/Staton8/bad/\"  #\"FromPramod/Staton8/good/TOA5_50453_CO2_44_2023_235_0000.dat\"\n",
    "InputFileExt = \".dat\"\n",
    "LengthToPlot = 86400  #Max = 86400\n",
    "WhichColumnToDisplay = \"CO2\"  #\"CO2\"  #BattVolt \n",
    "\n",
    "\n",
    "############COnstant Parameters#############\n",
    "OutputPath = InputPath + \"/OutFiles/\"\n",
    "OutputFileExt = \".csv\"\n",
    "OutputCleanedExt = \"_Cleaned.csv\"\n",
    "MaxLength = 86400\n",
    "\n",
    "\n",
    "#Read Input file and convert to csv\n",
    "df = pd.read_csv(InputPath + FileName + InputFileExt)\n",
    "# df = pd.read_csv(\"FromPramod/Station3/TOA5_50455_CO2_56_2023_257_0000.dat\")\n",
    "\n",
    "#check if output path exists , if no create it\n",
    "if not (os.path.exists(OutputPath)):\n",
    "    os.makedirs(OutputPath)\n",
    "    print(\"Creating New Directory- OutFiles\")\n",
    "\n",
    "df.to_csv(OutputPath + FileName + OutputFileExt)\n",
    "\n",
    "df2 = pd.read_csv(OutputPath + FileName + OutputFileExt,header=None)\n",
    "# print(df2.head(2))\n",
    "\n",
    "#Drop index 1,3,4 -- ie, 0,2,3\n",
    "df2_drop = df2.drop([df2.index[0], df2.index[2],df2.index[3]])\n",
    "# print(df2_drop.head(4))\n",
    "\n",
    "#Keep 200 lines\n",
    "RowsToKeep = 200\n",
    "\n",
    "\n",
    "\n",
    "#Assign new header as columns\n",
    "new_header = df2_drop.iloc[0]\n",
    "df2_drop = df2_drop[1:]\n",
    "df2_drop.columns = new_header\n",
    "df_new = df2_drop.reset_index(drop=True)\n",
    "# print(df2_drop.head(4))\n",
    "# print(df_new.head(3))\n",
    "#Get first 200 Rows\n",
    "df_firstFew = df_new.head(RowsToKeep)\n",
    "\n",
    "print(df_firstFew.size)\n",
    "print(df_firstFew.tail(5))\n",
    "df_firstFew.to_csv(OutputPath + FileName + \"Stripped\" + OutputFileExt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-22\n",
      "<class 'datetime.date'>\n",
      "DatetimeIndex(['2023-09-22 00:00:00', '2023-09-22 00:00:01',\n",
      "               '2023-09-22 00:00:02', '2023-09-22 00:00:03'],\n",
      "              dtype='datetime64[ns]', freq='S')\n",
      "2023-09-22 00:00:01\n",
      "2023-09-22 00:00:00\n",
      "DatetimeIndex(['2023-09-22 00:00:01', '2023-09-22 00:00:02',\n",
      "               '2023-09-22 00:00:03', '2023-09-22 00:00:04'],\n",
      "              dtype='datetime64[ns]', freq='S')\n",
      "Printing end date\n",
      "DatetimeIndex(['2023-09-22 23:59:56', '2023-09-22 23:59:57',\n",
      "               '2023-09-22 23:59:58', '2023-09-22 23:59:59',\n",
      "               '2023-09-23 00:00:00'],\n",
      "              dtype='datetime64[ns]', freq='S')\n",
      "                     Unnamed: 0            TIMESTAMP   RECORD  Year  Month  \\\n",
      "TIMESTAMP                                                                    \n",
      "2023-09-22 09:29:58           0  2023-09-22 09:29:58  3569647  2023      9   \n",
      "2023-09-22 09:29:59           1  2023-09-22 09:29:59  3569648  2023      9   \n",
      "2023-09-22 09:30:05           7  2023-09-22 09:30:05  3569654  2023      9   \n",
      "\n",
      "                     Day_of_Month  Day_of_Week  Day_of_Year  Hour  Minute  \\\n",
      "TIMESTAMP                                                                   \n",
      "2023-09-22 09:29:58            22            6          265     9      29   \n",
      "2023-09-22 09:29:59            22            6          265     9      29   \n",
      "2023-09-22 09:30:05            22            6          265     9      30   \n",
      "\n",
      "                     ...       CO2       H2O  wind_speed  wind_direction  \\\n",
      "TIMESTAMP            ...                                                   \n",
      "2023-09-22 09:29:58  ...  0.004254 -0.000669        0.65             139   \n",
      "2023-09-22 09:29:59  ...  0.000130 -0.000546        0.71             130   \n",
      "2023-09-22 09:30:05  ... -0.000645 -0.000326        0.47             117   \n",
      "\n",
      "                     diag  IncomingSW  OutgoingSW  IncomingLW  OutgoingLW  \\\n",
      "TIMESTAMP                                                                   \n",
      "2023-09-22 09:29:58     0       345.2        93.9       338.6       443.9   \n",
      "2023-09-22 09:29:59     0       345.2        93.9       338.6       443.9   \n",
      "2023-09-22 09:30:05     0       351.2        95.3       338.1       443.9   \n",
      "\n",
      "                     Albedo  \n",
      "TIMESTAMP                    \n",
      "2023-09-22 09:29:58   0.272  \n",
      "2023-09-22 09:29:59   0.272  \n",
      "2023-09-22 09:30:05   0.271  \n",
      "\n",
      "[3 rows x 29 columns]\n",
      "printing combined df\n",
      "Printing merged df\n",
      "                     Unnamed: 0            TIMESTAMP     RECORD    Year  \\\n",
      "2023-09-22 09:29:58         0.0  2023-09-22 09:29:58  3569647.0  2023.0   \n",
      "2023-09-22 09:29:59         1.0  2023-09-22 09:29:59  3569648.0  2023.0   \n",
      "2023-09-22 09:30:00         NaN                  NaN        NaN     NaN   \n",
      "2023-09-22 09:30:01         NaN                  NaN        NaN     NaN   \n",
      "2023-09-22 09:30:02         NaN                  NaN        NaN     NaN   \n",
      "...                         ...                  ...        ...     ...   \n",
      "2023-09-22 09:30:54        56.0  2023-09-22 09:30:54  3569703.0  2023.0   \n",
      "2023-09-22 09:30:55        57.0  2023-09-22 09:30:55  3569704.0  2023.0   \n",
      "2023-09-22 09:30:56        58.0  2023-09-22 09:30:56  3569705.0  2023.0   \n",
      "2023-09-22 09:30:57        59.0  2023-09-22 09:30:57  3569706.0  2023.0   \n",
      "2023-09-22 09:30:58        60.0  2023-09-22 09:30:58  3569707.0  2023.0   \n",
      "\n",
      "                     Month  Day_of_Month  Day_of_Week  Day_of_Year  Hour  \\\n",
      "2023-09-22 09:29:58    9.0          22.0          6.0        265.0   9.0   \n",
      "2023-09-22 09:29:59    9.0          22.0          6.0        265.0   9.0   \n",
      "2023-09-22 09:30:00    NaN           NaN          NaN          NaN   NaN   \n",
      "2023-09-22 09:30:01    NaN           NaN          NaN          NaN   NaN   \n",
      "2023-09-22 09:30:02    NaN           NaN          NaN          NaN   NaN   \n",
      "...                    ...           ...          ...          ...   ...   \n",
      "2023-09-22 09:30:54    9.0          22.0          6.0        265.0   9.0   \n",
      "2023-09-22 09:30:55    9.0          22.0          6.0        265.0   9.0   \n",
      "2023-09-22 09:30:56    9.0          22.0          6.0        265.0   9.0   \n",
      "2023-09-22 09:30:57    9.0          22.0          6.0        265.0   9.0   \n",
      "2023-09-22 09:30:58    9.0          22.0          6.0        265.0   9.0   \n",
      "\n",
      "                     Minute  ...       CO2       H2O  wind_speed  \\\n",
      "2023-09-22 09:29:58    29.0  ...  0.004254 -0.000669        0.65   \n",
      "2023-09-22 09:29:59    29.0  ...  0.000130 -0.000546        0.71   \n",
      "2023-09-22 09:30:00     NaN  ...       NaN       NaN         NaN   \n",
      "2023-09-22 09:30:01     NaN  ...       NaN       NaN         NaN   \n",
      "2023-09-22 09:30:02     NaN  ...       NaN       NaN         NaN   \n",
      "...                     ...  ...       ...       ...         ...   \n",
      "2023-09-22 09:30:54    30.0  ... -0.004292 -0.000884        0.49   \n",
      "2023-09-22 09:30:55    30.0  ... -0.006187 -0.000186        0.41   \n",
      "2023-09-22 09:30:56    30.0  ... -0.004403 -0.000782        0.42   \n",
      "2023-09-22 09:30:57    30.0  ... -0.006846 -0.000688        0.50   \n",
      "2023-09-22 09:30:58    30.0  ... -0.004780 -0.000705        0.49   \n",
      "\n",
      "                     wind_direction  diag  IncomingSW  OutgoingSW  IncomingLW  \\\n",
      "2023-09-22 09:29:58           139.0   0.0       345.2        93.9       338.6   \n",
      "2023-09-22 09:29:59           130.0   0.0       345.2        93.9       338.6   \n",
      "2023-09-22 09:30:00             NaN   NaN         NaN         NaN         NaN   \n",
      "2023-09-22 09:30:01             NaN   NaN         NaN         NaN         NaN   \n",
      "2023-09-22 09:30:02             NaN   NaN         NaN         NaN         NaN   \n",
      "...                             ...   ...         ...         ...         ...   \n",
      "2023-09-22 09:30:54           127.0   0.0       326.8        88.8       338.2   \n",
      "2023-09-22 09:30:55           129.0   0.0       326.8        88.8       338.2   \n",
      "2023-09-22 09:30:56           129.0   0.0       326.8        88.8       338.2   \n",
      "2023-09-22 09:30:57           120.0   0.0       330.7        89.9       338.5   \n",
      "2023-09-22 09:30:58           111.0   0.0       330.7        89.9       338.5   \n",
      "\n",
      "                     OutgoingLW  Albedo  \n",
      "2023-09-22 09:29:58       443.9   0.272  \n",
      "2023-09-22 09:29:59       443.9   0.272  \n",
      "2023-09-22 09:30:00         NaN     NaN  \n",
      "2023-09-22 09:30:01         NaN     NaN  \n",
      "2023-09-22 09:30:02         NaN     NaN  \n",
      "...                         ...     ...  \n",
      "2023-09-22 09:30:54       441.6   0.272  \n",
      "2023-09-22 09:30:55       441.6   0.272  \n",
      "2023-09-22 09:30:56       441.6   0.272  \n",
      "2023-09-22 09:30:57       441.4   0.272  \n",
      "2023-09-22 09:30:58       441.4   0.271  \n",
      "\n",
      "[61 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "#read from csv and \n",
    "df_Stripped = pd.read_csv(OutputPath + FileName + \"Stripped\" + OutputFileExt)\n",
    "\n",
    "df_Stripped_drop6rows = df_Stripped.drop([2,3,4])\n",
    "df_Stripped_dropped2 = df_Stripped.drop(df_Stripped.index[2:7])\n",
    "# print(df_Stripped_drop6rows.head(10))\n",
    "# print(df_Stripped_dropped2.head(10))\n",
    "# print(df_Stripped.head(2))\n",
    "\n",
    "GetDate1 = pd.to_datetime(df_Stripped[\"TIMESTAMP\"][0])\n",
    "print(GetDate1.date())\n",
    "print(type(GetDate1.date()))\n",
    "GetDate2 = GetDate1.date()\n",
    "#create a new date time stamp \n",
    "dateTimeRange = pd.date_range(GetDate2,periods=86400, freq='s')\n",
    "print(dateTimeRange[0:4])\n",
    "#Get range of values\n",
    "\n",
    "start_time = pd.Timestamp(str(GetDate2) + \" 00:00:01\")\n",
    "end_time = pd.Timestamp(str(GetDate2) + \" 00:00:00\")\n",
    "print(start_time)\n",
    "print(end_time)\n",
    "GetTimeRange = pd.date_range(start_time,periods=86400, freq='1s')\n",
    "print(GetTimeRange[0:4])\n",
    "print(\"Printing end date\")\n",
    "print(GetTimeRange[-5:])\n",
    "#create a dataframe from GetTimeRange\n",
    "df_ts = pd.DataFrame(index=GetTimeRange)\n",
    "\n",
    "# print('***********')\n",
    "df_TimeStamp = pd.to_datetime(df_Stripped_dropped2[\"TIMESTAMP\"])\n",
    "# df_Stripped_Reindxed = df_Stripped_dropped2.reindex(df_TimeStamp , method='ffill')\n",
    "# df_Stripped_Reindxed2 = df_Stripped_dropped2.set_index(df_Stripped_dropped2[\"TIMESTAMP\"])\n",
    "df_Stripped_SetIndex = df_Stripped_dropped2.set_index(df_TimeStamp)\n",
    "print(df_Stripped_SetIndex.head(3))\n",
    "\n",
    "ColumnNamesFromStripped = df_Stripped.columns\n",
    "# df_ts.columns = ColumnNamesFromStripped\n",
    "combined_df = df_ts.combine_first(df_Stripped_SetIndex)\n",
    "print(\"printing combined df\")\n",
    "# print(combined_df.head(3))\n",
    "\n",
    "# Merge the two DataFrames, filling in NaN for missing values in df2\n",
    "merged_df = pd.concat([df_Stripped_SetIndex, df_ts], axis=1, join='outer')\n",
    "print(\"Printing merged df\")\n",
    "# print(merged_df.head(3))\n",
    "# print(merged_df[merged_df.index[\"2023-09-22 09:29:58\":\"2023-09-22 09:30:58\"]])\n",
    "print(merged_df.loc[\"2023-09-22 09:29:58\":\"2023-09-22 09:30:58\"])\n",
    "merged_df.to_csv(OutputPath + FileName + \"Merged\" + OutputFileExt)\n",
    "#Use set_index to set the index now\n",
    "# df_Stripped_SetIndex2 = df_Stripped_dropped2.set_index(GetTimeRange)\n",
    "# # df_Stripped_SetIndex2 = df_Stripped_dropped2.reset_index(GetTimeRange)\n",
    "# print(df_Stripped_SetIndex2.head(3))\n",
    "\n",
    "# # print(df_Stripped_Reindxed2.head())\n",
    "\n",
    "# df_Stripped_Resample = df_Stripped_Reindxed2.resample('s').asfreq()\n",
    "# print(df_Stripped_Resample.head())\n",
    "\n",
    "# timestamp = pd.date_range()\n",
    "#Check if the \n",
    "\n",
    "# print(type(df_Stripped[\"TIMESTAMP\"][0]))\n",
    "# df_Stripped_Clean = df_Stripped.loc[:,~df_Stripped.columns.str.contains('^Unnamed')]\n",
    "# # print(df_Stripped_Clean.head(2))\n",
    "# df_TimeStamp = df_Stripped[\"TIMESTAMP\"]\n",
    "# print(len(df_TimeStamp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Stripped_Clean.index = pd.to_datetime(df_Stripped_Clean.index)\n",
    "# GetDate = \"2023-09-22\"\n",
    "# df_Stripped_Clean.TIMESTAMP = pd.to_datetime(df_Stripped_Clean.TIMESTAMP)\n",
    "# df5min = df_Stripped_Clean.set_index('TIMESTAMP').resample('5Min')\n",
    "# print(df5min)\n",
    "# df_Stripped_Clean = df_Stripped_Clean.set_index('TIMESTAMP')\n",
    "# df5min = df_Stripped_Clean.resample('5Min', on='TIMESTAMP').first().drop('TIMESTAMP', 1).reset_index()\n",
    "\n",
    "\n",
    "# print(df_Stripped_Clean.head(2))\n",
    "# df_Stripped_Clean_Timestamp = df_Stripped_Clean['TIMESTAMP'][2:]\n",
    "# df_Stripped_Clean_ToTimestamp = pd.to_datetime(df_Stripped_Clean_Timestamp)\n",
    "# df_Stripped_ReSample = df_Stripped_Clean_ToTimestamp.resample(\"1S\").asfreq()\n",
    "# df_Stripped_ReSample = df_Stripped_Clean_ToTimestamp.resample(\"1S\").ffill()\n",
    "# df_Stripped_ToTimestamp = pd.to_datetime(df_Stripped_Timestamp)\n",
    "# print(type(df_Stripped_ToTimestamp[0]))\n",
    "# df_Stripped_Resample = df_Stripped_ToTimestamp.resample(\"S\").asfreq()\n",
    "# print(df_Stripped_Resample.head(3))\n",
    "# df['date'] = df_Stripped_ToTimestamp.date\n",
    "# df_Stripped2 = df_Stripped[2:]\n",
    "#Try resampling on df_Stripped\n",
    "# df_Stripped_Resampled = df_Stripped2.resample(\"S\").asfreq()\n",
    "# df_Stripped_Timestamp.to_csv(OutputPath + FileName + \"StrippedSampled\" + OutputFileExt)\n",
    "# print(df['date'][0])\n",
    "# GetDate =  df_Stripped_ToTimestamp[0].date             #df_Stripped_Timestamp[0].dt.date\n",
    "# print(GetDate)\n",
    "# print(df_Stripped.head(2))\n",
    "# print(df_Stripped.size)\n",
    "# # print(df_Stripped_Timestamp.size)\n",
    "# # print(df_Stripped_Timestamp.head(2))\n",
    "# idx = pd.date_range('2018-01-01 00:00:01', periods=86400, freq='s')\n",
    "# # print(idx)\n",
    "# print(type(idx))\n",
    "# print(idx[0])\n",
    "# print(len(idx))\n",
    "\n",
    "\n",
    "# LengthToPrint = 6\n",
    "# count = 0\n",
    "# for i in range(0,len(idx)):\n",
    "#     if count < LengthToPrint:\n",
    "#         print(\"i = {}, idx= {}\".format(i, idx[i]))\n",
    "#     count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Check the length of data = 86400 ie, 24*60*60 secs in a day\n",
    "LengthOfData = df_new[\"TIMESTAMP\"].count()\n",
    "if( df_new[\"TIMESTAMP\"].count() < MaxLength):\n",
    "    TotalLengthOfBadData = df_new[\"TIMESTAMP\"].count()\n",
    "    print(\"Max length of data = {}\".format(LengthToPlot))\n",
    "    if LengthToPlot > TotalLengthOfBadData :\n",
    "        LengthToPlot = TotalLengthOfBadData\n",
    "    \n",
    "elif df_new[\"TIMESTAMP\"].count() == MaxLength:\n",
    "    print(\"Length = 86400 -- Good data!\")\n",
    "else:\n",
    "    print(\"Length > MaxLength -- Freq>1 Hz !!!\")\n",
    "    exit(-1)\n",
    "\n",
    "\n",
    "# columnsToDrop = [\"RECORD\",\"Year\", \"Month\",\"Day_of_Month\",\"Day_of_Week\",\"Day_of_Year\",\"Hour\",\"Minute\",\"Second\"]\n",
    "columnsToDrop = [\"RECORD\",\"Year\", \"Month\",\"Day_of_Month\",\"Day_of_Week\",\"Day_of_Year\",\"Minute\",\"Second\"]\n",
    "df_Clean = df_new.drop(columnsToDrop, axis=1)\n",
    "# print(df_Clean.count())\n",
    "\n",
    "df_Clean.to_csv(OutputPath + FileName + OutputCleanedExt)\n",
    "\n",
    "\n",
    "\n",
    "#dataframes available : \n",
    "df_Clean = pd.read_csv(OutputPath + FileName + OutputCleanedExt)\n",
    "# print(df_Clean.head(5))\n",
    "#Delte first \n",
    "\n",
    "df_Clean = df_Clean.loc[:,~df_Clean.columns.str.contains('^Unnamed')]\n",
    "print(df_Clean.head(5))\n",
    "\n",
    "#Plot CO2\n",
    "df_WhichColumn = df_Clean[WhichColumnToDisplay]\n",
    "df_WhichColumn_Small = df_WhichColumn[:LengthToPlot]\n",
    "df_WhichColumn_Small.plot()\n",
    "\n",
    "\n",
    "plt.title(WhichColumnToDisplay + \" Plot\")\n",
    "plt.savefig(OutputPath + FileName + \"_\" + WhichColumnToDisplay + \"_Plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0            TIMESTAMP  BattVolt  PTemp  AirTemp     Rh  \\\n",
      "0           0  2023-09-22 09:29:58      8.17  23.28    27.21  23.63   \n",
      "1           1  2023-09-22 09:29:59      8.17  23.28    27.07  23.29   \n",
      "2           2  2023-09-22 09:30:00      8.17  23.28    27.17  23.41   \n",
      "3           3  2023-09-22 09:30:01      8.18  23.28    27.08  23.16   \n",
      "4           4  2023-09-22 09:30:02      8.18  23.28    27.07  23.16   \n",
      "\n",
      "   SBTemp_1360  TargTemp_1360  TmV_1360    PAR       CO2       H2O wind_speed  \\\n",
      "0        29.65          24.47 -0.266155  767.2  0.004254 -0.000669       0.65   \n",
      "1        29.65          24.38 -0.270545  769.3  0.000130 -0.000546       0.71   \n",
      "2        29.65          24.34 -0.272572  768.2  0.002119 -0.000581        0.7   \n",
      "3        29.65          24.34 -0.272376  765.1  0.000656 -0.000464       0.66   \n",
      "4        29.65          24.33 -0.273166  762.9  0.001963  0.000136       0.75   \n",
      "\n",
      "  wind_direction diag  IncomingSW  OutgoingSW  IncomingLW  OutgoingLW  Albedo  \n",
      "0            139    0       345.2        93.9       338.6       443.9   0.272  \n",
      "1            130    0       345.2        93.9       338.6       443.9   0.272  \n",
      "2            124    0       345.2        93.9       338.6       443.9   0.272  \n",
      "3            126    0       345.2        93.9       338.6       443.9   0.272  \n",
      "4            120    0       351.2        95.3       338.1       443.9   0.272  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/abhinav/Documents/SourceCodeGeneral/Python/TryCleaningData3_PlottingSingleCol.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abhinav/Documents/SourceCodeGeneral/Python/TryCleaningData3_PlottingSingleCol.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(df_Clean\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abhinav/Documents/SourceCodeGeneral/Python/TryCleaningData3_PlottingSingleCol.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# resampel\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/abhinav/Documents/SourceCodeGeneral/Python/TryCleaningData3_PlottingSingleCol.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m df5min \u001b[39m=\u001b[39m df_Clean\u001b[39m.\u001b[39mresample(\u001b[39m'\u001b[39m\u001b[39m5Min\u001b[39m\u001b[39m'\u001b[39m, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTIMESTAMP\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mfirst()\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mTIMESTAMP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/abhinav/Documents/SourceCodeGeneral/Python/TryCleaningData3_PlottingSingleCol.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(df5min\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_VSCode/lib/python3.11/site-packages/pandas/core/generic.py:9435\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[0;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[1;32m   9432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   9433\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 9435\u001b[0m \u001b[39mreturn\u001b[39;00m get_resampler(\n\u001b[1;32m   9436\u001b[0m     cast(\u001b[39m\"\u001b[39m\u001b[39mSeries | DataFrame\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m),\n\u001b[1;32m   9437\u001b[0m     freq\u001b[39m=\u001b[39mrule,\n\u001b[1;32m   9438\u001b[0m     label\u001b[39m=\u001b[39mlabel,\n\u001b[1;32m   9439\u001b[0m     closed\u001b[39m=\u001b[39mclosed,\n\u001b[1;32m   9440\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   9441\u001b[0m     kind\u001b[39m=\u001b[39mkind,\n\u001b[1;32m   9442\u001b[0m     convention\u001b[39m=\u001b[39mconvention,\n\u001b[1;32m   9443\u001b[0m     key\u001b[39m=\u001b[39mon,\n\u001b[1;32m   9444\u001b[0m     level\u001b[39m=\u001b[39mlevel,\n\u001b[1;32m   9445\u001b[0m     origin\u001b[39m=\u001b[39morigin,\n\u001b[1;32m   9446\u001b[0m     offset\u001b[39m=\u001b[39moffset,\n\u001b[1;32m   9447\u001b[0m     group_keys\u001b[39m=\u001b[39mgroup_keys,\n\u001b[1;32m   9448\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_VSCode/lib/python3.11/site-packages/pandas/core/resample.py:1970\u001b[0m, in \u001b[0;36mget_resampler\u001b[0;34m(obj, kind, **kwds)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m \u001b[39mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m tg \u001b[39m=\u001b[39m TimeGrouper(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 1970\u001b[0m \u001b[39mreturn\u001b[39;00m tg\u001b[39m.\u001b[39m_get_resampler(obj, kind\u001b[39m=\u001b[39mkind)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_VSCode/lib/python3.11/site-packages/pandas/core/resample.py:2160\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[1;32m   2152\u001b[0m     \u001b[39mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[1;32m   2153\u001b[0m         obj,\n\u001b[1;32m   2154\u001b[0m         timegrouper\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2157\u001b[0m         gpr_index\u001b[39m=\u001b[39max,\n\u001b[1;32m   2158\u001b[0m     )\n\u001b[0;32m-> 2160\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2161\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnly valid with DatetimeIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2162\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2163\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got an instance of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(ax)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2164\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "#Try with bad data -- \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "############COnstant Parameters#############\n",
    "OutputPath = InputPath + \"/OutFiles/\"\n",
    "OutputFileExt = \".csv\"\n",
    "OutputCleanedExt = \"_Cleaned.csv\"\n",
    "MaxLength = 86400\n",
    "\n",
    "############Configurable Parameters#############\n",
    "FileName = \"TOA5_50453_CO2_77_2023_265_0929\"\n",
    "InputPath = \"FromPramod/Staton8/bad/\"  #\"FromPramod/Staton8/good/TOA5_50453_CO2_44_2023_235_0000.dat\"\n",
    "InputFileExt = \".dat\"\n",
    "LengthToPlot = 86400  #Max = 86400\n",
    "WhichColumnToDisplay = \"CO2\"  #\"CO2\"  #BattVolt \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Read Input file and convert to csv\n",
    "# df = pd.read_csv(InputPath + FileName + InputFileExt)\n",
    "# # df = pd.read_csv(\"FromPramod/Station3/TOA5_50455_CO2_56_2023_257_0000.dat\")\n",
    "\n",
    "# #check if output path exists , if no create it\n",
    "# if not (os.path.exists(OutputPath)):\n",
    "#     os.makedirs(OutputPath)\n",
    "#     print(\"Creating New Directory- OutFiles\")\n",
    "\n",
    "# df.to_csv(OutputPath + FileName + OutputFileExt)\n",
    "\n",
    "df_Clean = pd.read_csv(OutputPath + FileName + OutputCleanedExt)\n",
    "print(df_Clean.head(5))\n",
    "\n",
    "# resampel\n",
    "# df5min = df_Clean.resample('5Min', on='TIMESTAMP').first().drop('TIMESTAMP', 1).reset_index()\n",
    "\n",
    "# print(df5min.head(5))\n",
    "#Resample for 1 -sec data & vlaue = NaN \n",
    "df_Clean[\"TIMESTAMP\"] = pd.to_datetime(df_Clean[\"TIMESTAMP\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_VSCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
